{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which TCRs affect a person's CMV status?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Peopleâ€™s pathogen exposure can be influenced by immunosequencing. In our project we focus on T cell repertoire and profile the T cell repertoire of 666 subjects with known cytomegalovirus (CMV) serostatus. To find out T cell receptors (TCRs) associated with CMV status, we implement two classification methods, which are beta-binomial model and naive bayes classifier. The classification methods would be also applied to predict the CMV status of a novel subject. Then leave-one-out cross validation is used to test the two methods. Also, we get LOO by stan to compare the two models.\n",
    "\n",
    "This project is a continuation of the study _Immunosequencing identifies signatures of cytomegalovirus exposure history and HLA-mediated effects on the T cell repertoire_ by Emerson et al (2017). We use the same data, but slightly differing statistical methods, as well as different objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "This project consists of four main parts: defining the significance levels of group differences in TCRs, Bayesian inference for the proportions of the TCRs in each group, creating a predictive model, as well as testing the model and comparing it to the Beta Binomial model of Emerson et al. (2017). \n",
    "\n",
    "## Fisher's exact test\n",
    "\n",
    "The number of possible TCR combinations is very large. For a subsample of 50 people, the total number of unique TCRs was over one million. For this reason, it is not plausible to use every TCR combination, even though they might carry some information.\n",
    "\n",
    "To counter this problem, the association between a given TCR and CMV status can be quantified. For this purpose, the Fisher's exact test was used. It provides an exact p-value, that denotes the probability that observed differences in proportion between two groups can be attributed to chance.\n",
    "\n",
    "We used the same significance level that the Emerson et al. (2017) use. It had been \n",
    "\n",
    "## Binomial model for the distribution of TCRs\n",
    "\n",
    "In the original paper, the TCRs that are associated with a positive CMV status were modeled as occuring with equal probability in each group. Thus, the paper only focused on the number of CMV associated, rather than the individual TCRs. We wanted to test the assumption that all TCRs have the same probability to appear within one CMV group.\n",
    "\n",
    "Another way to model the TCRs appearing would be to denote a probability $p_{ij}$ for each $TCR_j$ to appear in a subject of CMV group $C_i$. Then the number of subjects with the given TCR would be binomially distributed. Based on this assumption, we can perform Bayesian inference and obtain the distribution of $p_{ij}$. Since the number of subjects with a TCR is binomially distributed, the likelihood of $p_{ij}$ is Beta distributed. Since we have no other data of the distribution of the TCRs, we use a uniform prior. Thus, the posterior is also a Beta distribution.\n",
    "\n",
    "\n",
    "## Naive Bayes classifier based on Bayesian inference\n",
    "\n",
    "The aim was to create a classifier based on the observations of the co-occurence of TCRs and CMV statuses. For this purpose, a Bernoulli naive Bayes classifier was used. A Bernoulli naive Bayes is good for the purpose: it uses binary data to sort samples into categories; in this case two. The model has the following structure\n",
    "\n",
    "$ p(C_i \\mid {\\bf x} ) \\propto p({\\bf x} \\mid C_i ) p(C_i) = p(C_i) \\Pi _{j=1}^{N} p(x_j \\mid C_i)^{b_j}(1 - p(x_j \\mid C_i))^{(1-b_j)} $\n",
    "\n",
    "where $b_j$ denotes the boolean value of having the TCR of the index $j$. \n",
    "\n",
    "Moreover, these probabilities are based on the expected values of the proportions in the sample. This means that $p(x_j \\mid C_i)$ is actually $p(x_j \\mid C_i, {\\bf x}_0)$ in this case. Because they are modelled as fixed probabilities in each group, these underlying probabilities are Beta distributed. Due to the independence assumption, we can first calculate the expected values of the probabilites, and then calculate the product for class probability estimation.\n",
    "\n",
    "The proportional values are transformed into probabilities\n",
    "\n",
    "$p(C_i \\mid {\\bf x} ) = \\frac{p({\\bf x} \\mid C_i ) p(C_i) }{ \\Sigma_{n=1}^K p({\\bf x} \\mid C_n ) p(C_n)} $\n",
    "\n",
    "where $K$ is the number of classes. Since $CMV^+$ and $CMV^-$ are complements, the number of classes is 2 in this case. Based on the observations ${\\bf x_0}$, the estimate becomes\n",
    "\n",
    "$p(C_i \\mid {\\bf x}, {\\bf x_0} ) =\\frac{P(T \\mid CMV^+) P(CMV^+)}{P(T \\mid CMV^+) + P(T \\mid CMV^-)}$\n",
    "$ = \\frac{\\Pi_{i=1}^n P(TCR_i \\mid CMV^+)P(CMV^+)}{ \\Pi_{i=1}^n P(TCR_i \\mid CMV^+)P(CMV^+) + \\Pi_{i=1}^n P(TCR_i \\mid CMV^-)P(CMV^+) } $\n",
    "\n",
    "$ = \\frac{\\frac{m_i^++1}{m_i^++2} \\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} }{ \\frac{m_i^++1}{m_i^++2}\\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} + \\frac{m_i^-+1}{m_i^-+2}\\Pi_{i=1}^n \\frac{l_i^-+1}{m_i^-+2} } $\n",
    "\n",
    "$ = \\frac{ (m_i^++1)\\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} }{ (m_i^++1)\\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} + (m_i^-+1)\\Pi_{i=1}^n \\frac{l_i^-+1}{m_i^-+2} } $\n",
    "\n",
    "\n",
    "where $l^+$ and $l^-$ denote occurences of the given TCR in the CMV positive group and CMV negative group respectively. Likewise, $m^+$ and $m^-$ denote the total sizes of these groups. $T$ denotes some combinations of TCRs occuring.\n",
    "\n",
    "\n",
    "## Cross validation (LOO)\n",
    "\n",
    "In order to compare our model with the one used in the original paper, some validation method must be used. For this purpose, we chose LOO cross validation.\n",
    "\n",
    "LOO cross validation essentially measures the predictive performance of a model for a given data point, when the model is based on all the other data.\n",
    "\n",
    "We use two different metrics for the . Because of its intuitive nature, accuracy (how many percent of data points are classified correctly) is used. To obtain a better of the probabilistic predictions the model is making, log-loss is used as well.\n",
    "\n",
    "The original purpose of this project was to compare the original, beta-binomial model to our multidimensional beta model. However, the original model proved to be difficult to implement, and we did not get proper results for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe some python code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The Fisher exact test produced rather straightforward results. A total of 164 TCRs had statistically significant differences in proportion between the two groups. \n",
    "\n",
    "The model based on individually beta distributed TCRs performed relatively well. In LOO terms, it had an accuracy of 86.2 per cent, while the average log loss was -12.153.\n",
    "\n",
    "We were able to compile the model that Emerson et al. (2017) suggested. We were, however, not able to create a predictor for this model. Thus, the results of the comparison between these models are indecisive. Moreover, Emerson et al. (2017) did not provide their statistics for accuracy and log-loss, even though they mentioned that they used it in the evaluation of CMV associated TCRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65858662 0.54623998]\n",
      " [0.03014943 0.56086935]\n",
      " [0.49236616 0.33564563]]\n"
     ]
    }
   ],
   "source": [
    "# definitely some code here\n",
    "\n",
    "import numpy as np\n",
    "data = np.random.rand(3,2)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Generally, the model performed well. However, many of the predicions were skewed towards either side of the probability. The model seemed to be over-confident.\n",
    "\n",
    "A significant problem in this study was the fact that the .\n",
    "\n",
    "Also, it is possible to also utilize TCRs with lower significance levels. The ones used in this dataset had very low p-values. LOO validation provides a good framework for testing the rigidity of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably no or little code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Emerson, Ryan O., et al. \"Immunosequencing identifies signatures of cytomegalovirus exposure history and HLA-mediated effects on the T cell repertoire.\" Nature genetics 49.5 (2017): 659."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "Maybe stan or even python code. Let's see if it's better to have it in the actual report sections or here. Perhaps include some of the code in the report and full code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8627145085803433\n",
      "Log loss -12.153544163581788\n",
      "total subjects 641 CMV negative 365\n"
     ]
    }
   ],
   "source": [
    "# python code\n",
    "\n",
    "import numpy as np\n",
    "from math import log\n",
    "import math\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "my_data = genfromtxt('supplementaryTables/SUPP.csv', delimiter=';')\n",
    "\n",
    "n_plus = 641 - 365\n",
    "n_minus = 365\n",
    "\n",
    "cmv_plus = my_data[:, 3] + 1\n",
    "cmv_minus = my_data[:, 4] + 1\n",
    "\n",
    "cmv_plus = cmv_plus[1:]\n",
    "cmv_minus = cmv_minus[1:]\n",
    "\n",
    "\n",
    "tcrs = []\n",
    "\n",
    "f = open('supplementaryTables/SUPP2.csv', \"r\")\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttcrs.append(line.rstrip())\n",
    "\n",
    "# binary data\n",
    "# each row is a person\n",
    "# the last number in the row is CMV class\n",
    "# all other data is TCR's\n",
    "\n",
    "# generate data with the following probabilities to have a given TCR\n",
    "# the last one denotes class, thus 1.0 and 0.0\n",
    "\n",
    "def classify(filename):\n",
    "\tstatus = True\n",
    "\tif \"negative\" in filename:\n",
    "\t\tstatus = False\n",
    "\n",
    "\tf = open(filename, \"r\")\n",
    "\n",
    "\tindices = []\n",
    "\ti = 0\n",
    "\tfor line in f.readlines():\n",
    "\t\tl = line.rstrip()\n",
    "\t\tif i > 0 and len(l) > 0:\n",
    "\t\t\tindex = tcrs.index(l)\n",
    "\t\t\tindices.append(tcrs.index(l))\n",
    "\t\ti += 1\n",
    "\n",
    "\tcontr = np.zeros(cmv_plus.shape)\n",
    "\tfor index in indices:\n",
    "\t\tcontr[index] = 1.0\n",
    "\n",
    "\t# calculate probabilities without the given data point\n",
    "\tprobs_1 = cmv_plus / (n_plus + 2)\n",
    "\tprobs_0 = (cmv_minus-contr) / (n_minus + 2)\n",
    "\n",
    "\tif status:\n",
    "\t\tprobs_1 = (cmv_plus-contr) / (n_plus + 2)\n",
    "\t\tprobs_0 = cmv_minus / (n_minus + 2)\n",
    "\n",
    "\tprobs_1 = np.abs(np.abs(probs_1 - contr) - 1)\n",
    "\tprobs_0 = np.abs(np.abs(probs_0 - contr) - 1)\n",
    "\n",
    "\t# calculate the likelihoods\n",
    "\tp_a = np.prod(probs_1) * (n_plus + 1) / (n_plus + 2)\n",
    "\tp_b = np.prod(probs_0) * (n_minus + 1) / (n_minus + 2)\n",
    "\n",
    "\t# calculate class probabilities based on the likelihoods\n",
    "\tp_total = p_a / (p_a + p_b)\n",
    "\n",
    "\t# return more likely class and its respective probability \n",
    "\tc = 1\n",
    "\tif p_b > p_a:\n",
    "\t\tc = 0\n",
    "\t\tp_total = 1 - p_total\n",
    "\n",
    "\treturn c, p_total\n",
    "\n",
    "\n",
    "def loo(files):\n",
    "\tlogloss = 0.0\n",
    "\tcorr = 0\n",
    "\ttot = 0\n",
    "\tnegs = 0\n",
    "\tfor file in files:\n",
    "\n",
    "\t\tif \"positive\" in file or \"negative\" in file:\n",
    "\t\t\ttot += 1\n",
    "\t\t\tcorrect_class = 1\n",
    "\t\t\tif \"negative\" in file:\n",
    "\t\t\t\tcorrect_class = 0\n",
    "\t\t\t\tnegs += 1\n",
    "\t\t\tc, p = classify(file)\n",
    "\n",
    "\t\t\t# prevent numerical errors in logloss\n",
    "\t\t\tif p < 0.0000000001:\n",
    "\t\t\t\tp = 0.0000000001\n",
    "\t\t\telif p > 1.0 - 0.0000000001:\n",
    "\t\t\t\tp = 1.0 - 0.0000000001\n",
    "\t\t\tif c == correct_class:\n",
    "\t\t\t\tcorr += 1\n",
    "\t\t\t\tlogloss += log(p)\n",
    "\t\t\tlogloss += log(1 - p)\n",
    "\n",
    "\tprint(\"Accuracy\", corr / tot)\n",
    "\tlogloss = logloss / tot\n",
    "\tprint(\"Log loss\", logloss)\n",
    "\tprint(\"total subjects\", tot, \"CMV negative\", negs)\n",
    "\n",
    "import glob\n",
    "fs = glob.glob(\"parsed3/*.csv\")\n",
    "\n",
    "loo(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// stan code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
