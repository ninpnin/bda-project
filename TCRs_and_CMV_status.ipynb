{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which TCRs affect a persons CMV status?\n",
    "\n",
    "This is a sketch for the final python notebook that we are going to submit. I've added a basic structural template that corresponds to the instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Peopleâ€™s pathogen exposure can be influenced by immunosequencing. In our project we focus on T cell repertoire and profile the T cell repertoire of 666 subjects with known cytomegalovirus (CMV) serostatus. To find out T cell receptors (TCRs) associated with CMV status, we implement two classification methods, which are beta-binomial model and naive bayes classifier. The classification methods would be also applied to predict the CMV status of a novel subject. Then leave-one-out cross validation is used to test the two methods. Also, we get LOO by stan to compare the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "Not mentioned in the questions but nice to have anyway. Makes the structure coherent.\n",
    "\n",
    "## Fisher's exact test\n",
    "\n",
    "The number of possible TCR combinations is very large. For a subsample of 50 people, the total number of unique TCRs was over one million. For this reason, it is not plausible to use every TCR combination, even though they might carry some information.\n",
    "\n",
    "To counter this problem, the association between a given TCR and CMV status can be quantified. For this purpose, the Fisher's exact test was used. It provides an exact p-value, that denotes the probability that observed differences in proportion between two groups can be attributed to chance.\n",
    "\n",
    "We used the same significance level that the authors of the original research paper used. That had been ,\n",
    "\n",
    "## Binomial model for the distribution of TCRs\n",
    "\n",
    "In the original paper, the TCRs that are associated with a positive CMV status were modeled as equal probability. Thus, the paper only focused on the number of CMV associated, rather than the individual TCRs. We wanted to test the assumption that all TCRs have the same probability to appear within one CMV group.\n",
    "\n",
    "Another way to model the TCRs appearing would be to denote a probability $p_{ij}$ for each $TCR_j$ to appear in a subject of group\n",
    "\n",
    "\n",
    "## Naive Bayes classifier\n",
    "\n",
    "For the classification, a Bernoulli naive Bayes classifier was used.\n",
    "\n",
    "The purpose of this is to test how well the naive Bayes model fits the data in contrast to the one used in the research paper.\n",
    "\n",
    "But first we need to define our model. A Bernoulli naive Bayes is good for the purpose: it uses binary data to sort samples into categories; in this case two. The model has the following structure\n",
    "\n",
    "$ p(C_i \\mid {\\bf x} ) \\propto p({\\bf x} \\mid C_i ) p(C_i) = p(C_i) \\Pi _{j=1}^{N} p(x_j \\mid C_i)^{b_j}(1 - p(x_j \\mid C_i))^{(1-b_j)} $\n",
    "\n",
    "where $b_j$ denotes the boolean value of having the TCR of the index $j$. \n",
    "\n",
    "Moreover, these probabilities are based on the expected values of the proportions in the sample. This means that $p(x_j \\mid C_i)$ is actually $p(x_j \\mid C_i, {\\bf x}_0)$ in this case. Because they are modelled as fixed probabilities in each group, these underlying probabilities are Beta distributed. Due to the independence assumption, we can first calculate the expected values of the probabilites, and then calculate the product for class probability estimation.\n",
    "\n",
    "The proportional values are transformed into probabilities\n",
    "\n",
    "$p(C_i \\mid {\\bf x} ) = \\frac{p({\\bf x} \\mid C_i ) p(C_i) }{ \\Sigma_{n=1}^K p({\\bf x} \\mid C_n ) p(C_n)} $\n",
    "\n",
    "where $K$ is the number of classes. Since $CMV^+$ and $CMV^-$ are complements, the number of classes is 2 in this case. Based on the observations ${\\bf x_0}$, the estimate becomes\n",
    "\n",
    "$p(C_i \\mid {\\bf x}, {\\bf x_0} ) =\\frac{P(T \\mid CMV^+) P(CMV^+)}{P(T \\mid CMV^+) + P(T \\mid CMV^-)}$\n",
    "$ = \\frac{\\Pi_{i=1}^n P(TCR_i \\mid CMV^+)P(CMV^+)}{ \\Pi_{i=1}^n P(TCR_i \\mid CMV^+)P(CMV^+) + \\Pi_{i=1}^n P(TCR_i \\mid CMV^-)P(CMV^+) } $\n",
    "\n",
    "$ = \\frac{\\frac{m_i^++1}{m_i^++2} \\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} }{ \\frac{m_i^++1}{m_i^++2}\\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} + \\frac{m_i^-+1}{m_i^-+2}\\Pi_{i=1}^n \\frac{l_i^-+1}{m_i^-+2} } $\n",
    "\n",
    "$ = \\frac{ (m_i^++1)\\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} }{ (m_i^++1)\\Pi_{i=1}^n \\frac{l_i^++1}{m_i^++2} + (m_i^-+1)\\Pi_{i=1}^n \\frac{l_i^-+1}{m_i^-+2} } $\n",
    "\n",
    "\n",
    "where $l^+$ and $l^-$ denote occurences of the given TCR in the CMV positive group and CMV negative group respectively. Likewise, $m^+$ and $m^-$ denote the total sizes of these groups.\n",
    "\n",
    "$P(CMV^+ \\mid TCR_1, TCR_2, \\dots TCR_n ) = \\frac{P(TCR_1, TCR_2, \\dots TCR_n \\mid CMV^+)}{P(TCR_1, TCR_2, \\dots TCR_n)}$\n",
    "\n",
    "Let's denote $TCR_1, TCR_2, \\dots TCR_n$ with $T$ for clarity.\n",
    "\n",
    "$P(CMD^+ \\mid T) = \\frac{P(T \\mid CMV^+) P(CMV^+)}{P(T)}$\n",
    "\n",
    "$ = \\frac{P(T \\mid CMV^+) P(CMV^+)}{P(T \\mid CMV^+) + P(T \\mid CMV^-)}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Cross validation (LOO)\n",
    "\n",
    "In order to compare our model with the one used in the original paper, some validation method must be used. For this purpose, we chose LOO cross validation.\n",
    "\n",
    "LOO cross validation essentially measures the predictive performance of a model for a given data point, when the model is based on all the other data.\n",
    "\n",
    "We use two different metrics for the . Because of its intuitive nature, accuracy (how many percent of data points are classified correctly) is used. To obtain a better of the probabilistic predictions the model is making, log-loss is used as well.\n",
    "\n",
    "The original purpose of this project was to compare the original, beta-binomial model to our multidimensional beta model. However, the original model proved to be difficult to implement, and we did not get proper results for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe some python code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Integral part of the report, I guess. Do the stuff described above. Have the code maybe here or possibly in the appendix.\n",
    "\n",
    "\n",
    "The model based on individually beta distributed TCRs performed relatively well. In LOO terms, it had an accuracy of 86.2 per cent, while the average log loss was -12.153."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65858662 0.54623998]\n",
      " [0.03014943 0.56086935]\n",
      " [0.49236616 0.33564563]]\n"
     ]
    }
   ],
   "source": [
    "# definitely some code here\n",
    "\n",
    "import numpy as np\n",
    "data = np.random.rand(3,2)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "There were a few questions about this. Try to write this chapter accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably no or little code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "Maybe stan or even python code. Let's see if it's better to have it in the actual report sections or here. Perhaps include some of the code in the report and full code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8627145085803433\n",
      "Log loss -12.153544163581788\n",
      "total subjects 641 CMV negative 365\n"
     ]
    }
   ],
   "source": [
    "# python code\n",
    "\n",
    "import numpy as np\n",
    "from math import log\n",
    "import math\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "my_data = genfromtxt('supplementaryTables/SUPP.csv', delimiter=';')\n",
    "\n",
    "n_plus = 641 - 365\n",
    "n_minus = 365\n",
    "\n",
    "cmv_plus = my_data[:, 3] + 1\n",
    "cmv_minus = my_data[:, 4] + 1\n",
    "\n",
    "cmv_plus = cmv_plus[1:]\n",
    "cmv_minus = cmv_minus[1:]\n",
    "\n",
    "\n",
    "tcrs = []\n",
    "\n",
    "f = open('supplementaryTables/SUPP2.csv', \"r\")\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttcrs.append(line.rstrip())\n",
    "\n",
    "# binary data\n",
    "# each row is a person\n",
    "# the last number in the row is CMV class\n",
    "# all other data is TCR's\n",
    "\n",
    "# generate data with the following probabilities to have a given TCR\n",
    "# the last one denotes class, thus 1.0 and 0.0\n",
    "\n",
    "def classify(filename):\n",
    "\tstatus = True\n",
    "\tif \"negative\" in filename:\n",
    "\t\tstatus = False\n",
    "\n",
    "\tf = open(filename, \"r\")\n",
    "\n",
    "\tindices = []\n",
    "\ti = 0\n",
    "\tfor line in f.readlines():\n",
    "\t\tl = line.rstrip()\n",
    "\t\tif i > 0 and len(l) > 0:\n",
    "\t\t\tindex = tcrs.index(l)\n",
    "\t\t\tindices.append(tcrs.index(l))\n",
    "\t\ti += 1\n",
    "\n",
    "\tcontr = np.zeros(cmv_plus.shape)\n",
    "\tfor index in indices:\n",
    "\t\tcontr[index] = 1.0\n",
    "\n",
    "\t# calculate probabilities without the given data point\n",
    "\tprobs_1 = cmv_plus / (n_plus + 2)\n",
    "\tprobs_0 = (cmv_minus-contr) / (n_minus + 2)\n",
    "\n",
    "\tif status:\n",
    "\t\tprobs_1 = (cmv_plus-contr) / (n_plus + 2)\n",
    "\t\tprobs_0 = cmv_minus / (n_minus + 2)\n",
    "\n",
    "\tprobs_1 = np.abs(np.abs(probs_1 - contr) - 1)\n",
    "\tprobs_0 = np.abs(np.abs(probs_0 - contr) - 1)\n",
    "\n",
    "\t# calculate the likelihoods\n",
    "\tp_a = np.prod(probs_1) * (n_plus + 1) / (n_plus + 2)\n",
    "\tp_b = np.prod(probs_0) * (n_minus + 1) / (n_minus + 2)\n",
    "\n",
    "\t# calculate class probabilities based on the likelihoods\n",
    "\tp_total = p_a / (p_a + p_b)\n",
    "\n",
    "\t# return more likely class and its respective probability \n",
    "\tc = 1\n",
    "\tif p_b > p_a:\n",
    "\t\tc = 0\n",
    "\t\tp_total = 1 - p_total\n",
    "\n",
    "\treturn c, p_total\n",
    "\n",
    "\n",
    "def loo(files):\n",
    "\tlogloss = 0.0\n",
    "\tcorr = 0\n",
    "\ttot = 0\n",
    "\tnegs = 0\n",
    "\tfor file in files:\n",
    "\n",
    "\t\tif \"positive\" in file or \"negative\" in file:\n",
    "\t\t\ttot += 1\n",
    "\t\t\tcorrect_class = 1\n",
    "\t\t\tif \"negative\" in file:\n",
    "\t\t\t\tcorrect_class = 0\n",
    "\t\t\t\tnegs += 1\n",
    "\t\t\tc, p = classify(file)\n",
    "\n",
    "\t\t\t# prevent numerical errors in logloss\n",
    "\t\t\tif p < 0.0000000001:\n",
    "\t\t\t\tp = 0.0000000001\n",
    "\t\t\telif p > 1.0 - 0.0000000001:\n",
    "\t\t\t\tp = 1.0 - 0.0000000001\n",
    "\t\t\tif c == correct_class:\n",
    "\t\t\t\tcorr += 1\n",
    "\t\t\t\tlogloss += log(p)\n",
    "\t\t\tlogloss += log(1 - p)\n",
    "\n",
    "\tprint(\"Accuracy\", corr / tot)\n",
    "\tlogloss = logloss / tot\n",
    "\tprint(\"Log loss\", logloss)\n",
    "\tprint(\"total subjects\", tot, \"CMV negative\", negs)\n",
    "\n",
    "import glob\n",
    "fs = glob.glob(\"parsed3/*.csv\")\n",
    "\n",
    "loo(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// stan code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
